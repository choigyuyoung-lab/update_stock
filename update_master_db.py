import os, re, time, logging, io
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any, List

import requests
import pandas as pd
import FinanceDataReader as fdr
from pykrx import stock
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# ---------------------------------------------------------
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")
IS_FULL_UPDATE = os.environ.get("IS_FULL_UPDATE", "False").lower() == "true"

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# [ìµœì í™”] ë°ì´í„°ì…‹ë³„ ìš°ì„ ìˆœìœ„ í—¤ë” ì •ì˜
HEADERS = {
    "KR_SECTOR": ['Sector', 'WICS ì—…ì¢…ëª…', 'ì—…ì¢…'],      # í•œêµ­ ëŒ€ë¶„ë¥˜
    "KR_INDUSTRY": ['Industry', 'ì£¼ìš”ì œí’ˆ', 'WICS ì œí’ˆ'], # í•œêµ­ ì„¸ë¶€ì„¤ëª…
    "US_SECTOR": ['Sector', 'GICS Sector'],              # ë¯¸êµ­ ëŒ€ë¶„ë¥˜
    "US_INDUSTRY": ['Industry', 'GICS Sub-Industry']     # ë¯¸êµ­ ì„¸ë¶€ì„¤ëª…
}

class StockAutomationEngine:
    def __init__(self):
        logger.info(f"ğŸ“¡ ì—”ì§„ ì‹œì‘ (ìˆ˜ë™ ì „ì²´ ì—…ë°ì´íŠ¸ ëª¨ë“œ: {IS_FULL_UPDATE})")
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        
        # 1. ë°ì´í„° ë¡œë“œ
        logger.info("â³ ì£¼ì‹/ETF ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        self.df_kr_desc = fdr.StockListing('KRX-DESC') # í•œêµ­ ì£¼ì‹ ìƒì„¸
        self.df_kr_etf = fdr.StockListing('ETF/KR')    # [ì¶”ê°€] í•œêµ­ ETF (ì´ë¦„ ì¡°íšŒìš©)
        
        self.df_sp500 = fdr.StockListing('S&P500')     # ë¯¸êµ­ ìš°ëŸ‰
        self.df_nasdaq = fdr.StockListing('NASDAQ')    # ë¯¸êµ­ ì „ì²´ 1
        self.df_nyse = fdr.StockListing('NYSE')        # ë¯¸êµ­ ì „ì²´ 2
        logger.info("âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ")
        
        # 2. ìš°ëŸ‰ì£¼ ë§µ êµ¬ì¶•
        self.blue_chip_map = {
            "S&P 500": self.df_sp500['Symbol'].tolist(),
            "NASDAQ 100": self._get_nas100(),
            "KOSPI 200": self._get_ks200(),
            "KOSDAQ GLOBAL": self._get_kglobal() 
        }

    def _get_nas100(self) -> List[str]:
        try:
            url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
            res = self.session.get(url, timeout=10)
            df = pd.read_html(io.StringIO(res.text))[4]
            col = 'Ticker' if 'Ticker' in df.columns else 'Symbol'
            return df[col].tolist()
        except: return []

    def _get_ks200(self) -> List[str]:
        for i in range(10):
            date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
            res = stock.get_index_portfolio_deposit_file("1028", date)
            if len(res) > 0: return res
        return []

    def _get_kglobal(self) -> List[str]:
        target = self.df_kr_desc[self.df_kr_desc['Market'].str.contains('KOSDAQ GLOBAL', case=False, na=False)]
        col = 'Code' if 'Code' in target.columns else 'Symbol'
        return target[col].tolist()

    def _get_val_from_headers(self, row, candidates: List[str]) -> Optional[str]:
        """ê°’ì´ ìˆìœ¼ë©´ ë¬¸ìì—´ ë°˜í™˜, ì—†ìœ¼ë©´ None ë°˜í™˜"""
        for col in candidates:
            if col in row.index and pd.notna(row[col]) and str(row[col]).strip() != "":
                return str(row[col]).strip()
        return None

    def get_stock_detail(self, clean_t: str) -> Dict[str, Any]:
        """í‹°ì»¤ ê¸°ë°˜ êµ­ê°€ë³„ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        res = {
            "name": "", "market": "ê¸°íƒ€", "origin": "",
            "kr_sector": None, "kr_ind": None,
            "us_sector": None, "us_ind": None
        }

        # 1. í•œêµ­ ì£¼ì‹ ê²€ìƒ‰ (KRX-DESC)
        kr_match = self.df_kr_desc[self.df_kr_desc['Code'] == clean_t]
        if not kr_match.empty:
            row = kr_match.iloc[0]
            mkt = "KOSDAQ" if "KOSDAQ" in str(row['Market']) else str(row['Market'])
            
            res.update({
                "name": row['Name'],
                "market": mkt,
                "origin": "KR",
                "kr_sector": self._get_val_from_headers(row, HEADERS['KR_SECTOR']),
                "kr_ind": self._get_val_from_headers(row, HEADERS['KR_INDUSTRY'])
            })
            return res

        # 2. [ì¶”ê°€] í•œêµ­ ETF ê²€ìƒ‰ (KRX-DESCì— ì—†ì„ ê²½ìš°)
        etf_match = self.df_kr_etf[self.df_kr_etf['Symbol'] == clean_t]
        if not etf_match.empty:
            row = etf_match.iloc[0]
            res.update({
                "name": row['Name'],  # ETF ì´ë¦„ í™•ë³´
                "market": "ETF",
                "origin": "KR",
                "kr_sector": "ETF",   # ì„¹í„°ëŠ” 'ETF'ë¡œ ë‹¨ìˆœ í‘œê¸°
                "kr_ind": None        # ì‚°ì—…ì€ ë¹„ì›Œë‘  (ê¹”ë”í•˜ê²Œ)
            })
            return res

        # 3. ë¯¸êµ­ ì£¼ì‹ ê²€ìƒ‰
        search_targets = [self.df_sp500, self.df_nasdaq, self.df_nyse]
        for df in search_targets:
            match = df[df['Symbol'] == clean_t]
            if not match.empty:
                row = match.iloc[0]
                if clean_t in self.df_nasdaq['Symbol'].values: mkt = "NASDAQ"
                elif clean_t in self.df_nyse['Symbol'].values: mkt = "NYSE"
                else: mkt = "NYSE"

                res.update({
                    "name": row['Name'],
                    "market": mkt,
                    "origin": "US",
                    "us_sector": self._get_val_from_headers(row, HEADERS['US_SECTOR']),
                    "us_ind": self._get_val_from_headers(row, HEADERS['US_INDUSTRY'])
                })
                return res

        return res

    def clean_ticker(self, raw_ticker: str) -> str:
        t = str(raw_ticker).strip().upper()
        if match := re.search(r'(\d{6})', t): return match.group(1)
        return re.split(r'[-.]', t)[0]

def process_page(page, engine, client):
    pid, props = page["id"], page["properties"]
    
    # í‹°ì»¤ ì½ê¸° (Title, RichText ëª¨ë‘ í˜¸í™˜)
    target_prop = props.get("í‹°ì»¤", {})
    ticker_rich = target_prop.get("title") or target_prop.get("rich_text")
    
    if not ticker_rich: 
        return
    
    raw_ticker = ticker_rich[0]["plain_text"].strip()
    clean_t = engine.clean_ticker(raw_ticker)

    # ì •ë³´ ì¡°íšŒ
    info = engine.get_stock_detail(clean_t)
    
    # ìš°ëŸ‰ì£¼ íƒœê·¸
    bc_tags = [{"name": label} for label, lst in engine.blue_chip_map.items() if clean_t in lst]

    def make_rich_text(text_val):
        if text_val:
            return {"rich_text": [{"text": {"content": text_val}}]}
        return {"rich_text": []} 

    update_props = {
        "ì¢…ëª©ëª…": make_rich_text(info["name"]),
        "Market": {"select": {"name": info["market"]}},
        
        "KR_ì„¹í„°": make_rich_text(info["kr_sector"]),
        "KR_ì‚°ì—…": make_rich_text(info["kr_ind"]),
        
        "US_ì„¹í„°": make_rich_text(info["us_sector"]),
        "US_ì—…ì¢…": make_rich_text(info["us_ind"]),
        
        "ì—…ë°ì´íŠ¸ ì¼ì": {"date": {"start": datetime.now().isoformat()}}
    }
    
    if "ìš°ëŸ‰ì£¼" in props:
        update_props["ìš°ëŸ‰ì£¼"] = {"multi_select": bc_tags}

    try:
        client.pages.update(page_id=pid, properties=update_props)
        logger.info(f"âœ… {raw_ticker} ({info['name']}) ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ {raw_ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def main():
    client = Client(auth=NOTION_TOKEN) 
    engine = StockAutomationEngine()
    
    cursor = None
    while True:
        query_params = {"database_id": MASTER_DATABASE_ID, "page_size": 100}
        if cursor: query_params["start_cursor"] = cursor
        
        if IS_FULL_UPDATE:
            logger.info("ğŸš€ ìˆ˜ë™ ëª¨ë“œ: ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì¢…ëª©ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
        else:
            logger.info("â³ ìë™ ëª¨ë“œ: 'ì¢…ëª©ëª…'ì´ ë¹„ì–´ ìˆëŠ” ì‹ ê·œ ì¢…ëª©ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            query_params["filter"] = {
                "property": "ì¢…ëª©ëª…",
                "rich_text": {"is_empty": True}
            }
        
        response = client.databases.query(**query_params) 
        pages = response.get("results", [])
        
        if not pages:
            logger.info("ğŸ“¢ ì²˜ë¦¬í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            break

        with ThreadPoolExecutor(max_workers=5) as executor:
            for page in pages:
                executor.submit(process_page, page, engine, client)
                time.sleep(0.1)
        
        if not response.get("has_more"): break
        cursor = response.get("next_cursor")

if __name__ == "__main__":
    main()
