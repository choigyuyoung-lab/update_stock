import os
import time
import requests
import re
import yfinance as yf
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# ---------------------------------------------------------
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")

# êµ¬ê¸€ ê²€ì¦ìš© API í‚¤
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
GOOGLE_CX = os.environ.get("GOOGLE_CX")

# [ì„¤ì •] íŠ¹ì • í‹°ì»¤ë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš© (ë¹„ì›Œë‘ë©´ ì „ì²´ ì‹¤í–‰)
TARGET_TICKERS = []

# ---------------------------------------------------------
# 2. í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ (í•˜ì´ë¸Œë¦¬ë“œ API + êµ¬ê¸€ ê²€ì¦)
# ---------------------------------------------------------
class StockCrawler:
    def __init__(self):
        # [í•µì‹¬] ëª¨ë°”ì¼ ì•„ì´í°ìœ¼ë¡œ ìœ„ì¥í•˜ì—¬ ë„¤ì´ë²„ ë³´ì•ˆì„ í†µê³¼í•©ë‹ˆë‹¤.
        self.mobile_headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        }

    # ------------------------------------------------------------------
    # [ê¸°ëŠ¥] êµ¬ê¸€ ê²€ìƒ‰ ê²€ì¦ (3ë‹¨ ìƒíƒœ ë°˜í™˜)
    # ------------------------------------------------------------------
    def verify_with_google(self, ticker, fetched_name):
        """
        ë°˜í™˜ê°’: (ìƒíƒœì½”ë“œ, ë¡œê·¸ë©”ì‹œì§€)
        - PASS: ê²€ì¦ ì„±ê³µ (âœ… ê²€ì¦ì™„ë£Œ)
        - SKIP: í• ë‹¹ëŸ‰ ì´ˆê³¼ ë˜ëŠ” API í‚¤ ì—†ìŒ (â³ ê²€ì¦ëŒ€ê¸°)
        - FAIL: ê²€ì¦ ì‹¤íŒ¨ (âš ï¸ í™•ì¸í•„ìš”)
        """
        if not GOOGLE_API_KEY or not GOOGLE_CX:
            return "SKIP", "(APIí‚¤ ì—†ìŒ/ê±´ë„ˆëœ€)"

        try:
            query = f"{ticker} ì£¼ì‹" if re.search(r'\d', ticker) else f"{ticker} stock"
            url = "https://www.googleapis.com/customsearch/v1"
            params = {'key': GOOGLE_API_KEY, 'cx': GOOGLE_CX, 'q': query, 'num': 2}
            
            res = requests.get(url, params=params, timeout=5)
            
            # [ì¤‘ìš”] í• ë‹¹ëŸ‰ ì´ˆê³¼(429) ë˜ëŠ” ê¶Œí•œ ì—†ìŒ(403) -> ê²€ì¦ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜
            if res.status_code in [429, 403]:
                return "SKIP", "(ì¼ì¼í• ë‹¹ëŸ‰ ì´ˆê³¼/ëŒ€ê¸°)"
            
            if res.status_code != 200:
                return "SKIP", f"(êµ¬ê¸€ ì—ëŸ¬ {res.status_code})"

            items = res.json().get('items', [])
            if not items:
                return "FAIL", "(êµ¬ê¸€ê²°ê³¼ ì—†ìŒ)"

            # ì´ë¦„ ë¹„êµ ë¡œì§ (í•µì‹¬ ë‹¨ì–´ í¬í•¨ ì—¬ë¶€)
            core_name = fetched_name.split()[0].replace(',', '').lower()
            is_matched = False
            for item in items:
                title = item.get('title', '').lower()
                snippet = item.get('snippet', '').lower()
                if (core_name in title or core_name in snippet) or \
                   (ticker.lower().split('.')[0] in title):
                    is_matched = True
                    break
            
            if is_matched:
                return "PASS", "+ êµ¬ê¸€ê²€ì¦ë¨"
            else:
                return "FAIL", "(ì´ë¦„ ë¶ˆì¼ì¹˜)"

        except Exception as e:
            return "SKIP", f"(ì‹œìŠ¤í…œ ì—ëŸ¬: {str(e)})"

    # ------------------------------------------------------------------
    # [1] í•œêµ­ ì£¼ì‹ (ëª¨ë°”ì¼ API)
    # ------------------------------------------------------------------
    def fetch_korean_stock(self, ticker):
        url = f"https://m.stock.naver.com/api/stock/{ticker}/integration"
        headers = self.mobile_headers.copy()
        headers['Referer'] = f"https://m.stock.naver.com/domestic/stock/{ticker}/total"
        headers['Origin'] = 'https://m.stock.naver.com'
        
        try:
            res = requests.get(url, headers=headers, timeout=5)
            if res.status_code != 200: return None

            data = res.json()
            name = data.get('stockName', ticker)
            
            # ì‚°ì—…ë¶„ë¥˜
            industry = ""
            if 'stocks' in data and data['stocks']:
                 industry = data['stocks'][0].get('industryCodeName', '')
            if not industry and 'stockItem' in data:
                industry = data['stockItem'].get('industryName', '')
            if not industry: industry = "í•œêµ­ì¦ì‹œ"

            # ê°œìš”
            total_infos = data.get('totalInfos', [])
            summary = ""
            for info in total_infos:
                if info.get('key') == 'summary_info':
                    summary = info.get('value', '')
                    break

            return {"name": name, "industry": industry, "summary": summary, "source": "ë„¤ì´ë²„(êµ­ë‚´)"}
        except Exception: return None

    # ------------------------------------------------------------------
    # [2] ë¯¸êµ­ ì£¼ì‹ (PC API + ëª¨ë°”ì¼ í—¤ë”)
    # ------------------------------------------------------------------
    def fetch_us_stock(self, ticker):
        suffixes = ['.O', '', '.K', '.N'] # ë‚˜ìŠ¤ë‹¥, NYSE, ì•„ë©•ìŠ¤ ìˆœ
        
        for suffix in suffixes:
            try:
                search_ticker = f"{ticker}{suffix}"
                url = f"https://api.stock.naver.com/stock/{search_ticker}/integration"
                
                headers = self.mobile_headers.copy()
                headers['Referer'] = f"https://m.stock.naver.com/worldstock/stock/{search_ticker}/total"
                headers['Origin'] = 'https://m.stock.naver.com'
                
                res = requests.get(url, headers=headers, timeout=5)
                if res.status_code != 200: continue

                data = res.json()
                if not data.get('symbolCode'): continue

                kor_name = data.get('stockName', '')
                eng_name = data.get('engStockName', '')
                final_name = kor_name if kor_name else (eng_name if eng_name else ticker)

                industry_map = data.get('industryCodeType', {})
                industry = industry_map.get('industryGroupKor', "ë¯¸êµ­ì£¼ì‹")
                summary = data.get('corpSummary', "")

                if final_name:
                    return {"name": final_name, "industry": industry, "summary": summary, "source": "ë„¤ì´ë²„(í•´ì™¸)"}
            except Exception: continue
        return None

    # ------------------------------------------------------------------
    # ë°ì´í„° ìˆ˜ì§‘ ì´ê´„
    # ------------------------------------------------------------------
    def get_data(self, ticker):
        raw_ticker = ticker.strip().upper()
        search_code = raw_ticker
        is_korea = False

        if (len(raw_ticker) == 6 and raw_ticker[0].isdigit()) or \
           raw_ticker.endswith('.KS') or raw_ticker.endswith('.KQ'):
            is_korea = True
            if '.' in raw_ticker: search_code = raw_ticker.split('.')[0]
        else:
            if '.' in raw_ticker: search_code = raw_ticker.split('.')[0]

        data = None
        if is_korea:
            data = self.fetch_korean_stock(search_code)
        else:
            data = self.fetch_us_stock(search_code)

        # ë°ì´í„°ê°€ ìˆìœ¼ë©´ êµ¬ê¸€ ê²€ì¦ ì§„í–‰
        if data:
            status, msg = self.verify_with_google(search_code, data['name'])
            data['ver_status'] = status # PASS, SKIP, FAIL
            data['source'] = f"{data['source']} {msg}"
        
        return data

# ---------------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ---------------------------------------------------------
def main():
    print(f"ğŸš€ [Master DB] ì „ì²´ ì¢…ëª© ì—…ë°ì´íŠ¸ ì‹œì‘ (í•„í„° ì—†ìŒ)")
    
    try:
        notion = Client(auth=NOTION_TOKEN)
        crawler = StockCrawler()
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    next_cursor = None
    processed_count = 0
    
    while True:
        try:
            # [ìˆ˜ì •ë¨] í•„í„° ì œê±° -> ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ í•­ëª©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            query_params = {
                "database_id": MASTER_DATABASE_ID,
                "page_size": 50
            }
            if next_cursor: query_params["start_cursor"] = next_cursor
            
            response = notion.databases.query(**query_params)
            pages = response.get("results", [])
            
            if not pages and processed_count == 0:
                print("âœ¨ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                break
            if not pages: break

            for page in pages:
                page_id = page["id"]
                props = page["properties"]
                
                ticker_list = props.get("í‹°ì»¤", {}).get("title", [])
                if not ticker_list: continue
                raw_ticker = ticker_list[0].get("plain_text", "").strip().upper()
                
                if TARGET_TICKERS and raw_ticker not in TARGET_TICKERS: continue

                print(f"ğŸ” ì¡°íšŒ ì¤‘: {raw_ticker} ...")
                
                data = crawler.get_data(raw_ticker)
                
                final_status = ""
                log_msg = ""
                upd_props = {}
                
                if data:
                    # [ìƒíƒœ ê²°ì • ë¡œì§]
                    v_stat = data.get('ver_status', 'SKIP')
                    
                    if v_stat == "PASS":
                        final_status = "âœ… ê²€ì¦ì™„ë£Œ"
                    elif v_stat == "SKIP":
                        final_status = "â³ ê²€ì¦ëŒ€ê¸°" # í• ë‹¹ëŸ‰ ì´ˆê³¼/ì—ëŸ¬ ë“±
                    else:
                        final_status = "âš ï¸ í™•ì¸í•„ìš”" # êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨
                    
                    log_msg = data['source']
                    summary_text = data['summary']
                    safe_summary = summary_text[:1900] + "..." if summary_text and len(summary_text) > 1900 else (summary_text or "")
                    
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": final_status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]},
                        "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": data['name']}}]},
                        "ì‚°ì—…ë¶„ë¥˜": {"rich_text": [{"text": {"content": data['industry']}}]}
                    }
                    if "íšŒì‚¬ê°œìš”" in props:
                        upd_props["íšŒì‚¬ê°œìš”"] = {"rich_text": [{"text": {"content": safe_summary}}]}
                    
                    print(f"   â”” {final_status}: {data['name']} ({log_msg})")
                else:
                    final_status = "âš ï¸ í™•ì¸í•„ìš”"
                    log_msg = "ë°ì´í„° ì—†ìŒ(ë„¤ì´ë²„/ì•¼í›„ ì‹¤íŒ¨)"
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": final_status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]}
                    }
                    print(f"   â”” ì‹¤íŒ¨: {log_msg}")

                notion.pages.update(page_id=page_id, properties=upd_props)
                processed_count += 1
                time.sleep(0.5) 

            if not response.get("has_more"): break
            next_cursor = response.get("next_cursor")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            break
            
    print(f"ğŸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì´ {processed_count}ê±´")

if __name__ == "__main__":
    main()
