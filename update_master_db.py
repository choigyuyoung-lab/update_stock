import os
import time
import requests
import yfinance as yf
from bs4 import BeautifulSoup
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ---------------------------------------------------------
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")

# [ì„¤ì •] ì „ì²´ ì—…ë°ì´íŠ¸ (íŠ¹ì • í‹°ì»¤ í…ŒìŠ¤íŠ¸ ì‹œ ì—¬ê¸°ì— ë¦¬ìŠ¤íŠ¸ ì‘ì„±)
TARGET_TICKERS = [] 

class StockCrawler:
    """
    ë³µì¡í•œ API í˜¸ì¶œ ëŒ€ì‹ , ë„¤ì´ë²„ ì›¹í˜ì´ì§€(HTML)ë¥¼ ì§ì ‘ ë¶„ì„í•˜ëŠ” 
    ê°€ì¥ ì „í†µì ì´ê³  ì•ˆì •ì ì¸ ë°©ì‹ì˜ í¬ë¡¤ëŸ¬
    """
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    def get_korea_stock(self, ticker):
        """
        [í•œêµ­ ì£¼ì‹] ë„¤ì´ë²„ ê¸ˆìœµ(PCë²„ì „) HTML í¬ë¡¤ë§
        ì¶œì²˜: https://finance.naver.com/item/main.naver?code=...
        """
        try:
            url = f"https://finance.naver.com/item/main.naver?code={ticker}"
            res = requests.get(url, headers=self.headers, timeout=10)
            
            # ë„¤ì´ë²„ ê¸ˆìœµì€ EUC-KR ì¸ì½”ë”©ì„ ì‚¬ìš© (ê¹¨ì§ ë°©ì§€)
            res.encoding = 'euc-kr' 
            soup = BeautifulSoup(res.text, 'html.parser')

            # 1. ì¢…ëª©ëª… (h2 íƒœê·¸)
            name_tag = soup.select_one('.wrap_company h2 a')
            if not name_tag:
                return None, "í˜ì´ì§€ êµ¬ì¡° ë‹¤ë¦„(ì¢…ëª©ëª… ì‹¤íŒ¨)"
            name = name_tag.text.strip()

            # 2. ì‚°ì—…ë¶„ë¥˜ (í•˜ì´ë¼ì´íŠ¸ ì„¹ì…˜ ë“±ì—ì„œ ìœ ì¶”í•˜ê±°ë‚˜ ì—…ì¢… ë€ íŒŒì‹±)
            # ë³´í†µ 'ì—…ì¢…' ë€ì´ ìƒë‹¨ì— ìˆìŒ
            industry = ""
            ind_tag = soup.select_one('.first .blind') # 'ì „ì¼' ë“±ì˜ í…ìŠ¤íŠ¸ê°€ ê±¸ë¦´ ìˆ˜ ìˆì–´ ìƒì„¸ íŒŒì‹± í•„ìš”
            # ë” í™•ì‹¤í•œ ë°©ë²•: ê¸°ì—…ê°œìš” ì„¹ì…˜ ê·¼ì²˜ì˜ ì—…ì¢… í™•ì¸
            # ë„¤ì´ë²„ ê¸ˆìœµ ë©”ì¸ì—ì„œëŠ” ì—…ì¢… ì°¾ê¸°ê°€ ê¹Œë‹¤ë¡œì›Œ WICS(ì„¹í„°) ì •ë³´ë¥¼ ë§ì´ ì”ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” 'íˆ¬ìì˜ê²¬/ëª©í‘œì£¼ê°€' í…Œì´ë¸” ì˜†ì´ë‚˜ 'ë™ì¼ì—…ì¢…ë¹„êµ' íƒ­ì„ ë´ì•¼í•˜ëŠ”ë°,
            # ê°„ë‹¨í•˜ê²Œ ê¸°ì—…ê°œìš” í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„ í˜¹ì€ ë¹ˆì¹¸.
            # (ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë°©ì‹: ë³´í†µ ETFê°€ ì•„ë‹ˆë©´ ì—…ì¢…ë€ì´ ëª…í™•ì¹˜ ì•Šì•„ 'ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥'ë§Œ êµ¬ë¶„í•˜ê¸°ë„ í•¨)
            # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì„±ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ë¹„ì›Œë‘ê±°ë‚˜, ì•„ë˜ ê¸°ì—…ê°œìš”ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            
            # 3. íšŒì‚¬ê°œìš” (ê¸°ì—…ê°œìš” div)
            summary_div = soup.select_one('#summary_info p')
            summary = summary_div.text.strip() if summary_div else "ê¸°ì—…ê°œìš” ì—†ìŒ"

            return {
                "name": name,
                "industry": "í•œêµ­ì¦ì‹œ", # HTML íŒŒì‹±ìœ¼ë¡œ ì •í™•í•œ ì—…ì¢… ì°¾ê¸°ëŠ” ë³µì¡í•˜ì—¬ ì¼ë‹¨ êµ­ê°€ë¡œ í‘œê¸°
                "summary": summary
            }, "âœ… ë„¤ì´ë²„ í¬ë¡¤ë§ ì„±ê³µ"

        except Exception as e:
            return None, f"í¬ë¡¤ë§ ì—ëŸ¬: {e}"

    def get_usa_stock_summary_kr(self, ticker):
        """
        [ë¯¸êµ­ ì£¼ì‹ ë³´ì¡°] ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹ì—ì„œ 'í•œê¸€ ê°œìš”'ë§Œ ì‚´ì§ ê¸ì–´ì˜¤ê¸°
        ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜
        """
        try:
            # ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹ ëª¨ë°”ì¼ í˜ì´ì§€ (ì—¬ê¸°ê°€ êµ¬ì¡°ê°€ ì œì¼ ë‹¨ìˆœí•¨)
            url = f"https://m.stock.naver.com/api/stock/{ticker}.O/integration" # .OëŠ” ë‚˜ìŠ¤ë‹¥/NYSE ë“± ìë™ë§¤ì¹­ë¨
            # ë§Œì•½ .Oê°€ ì•ˆë¨¹íˆë©´ ê²€ìƒ‰ APIë¥¼ ì¨ì•¼í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì‹œë„ë§Œ í•¨.
            # ì´ë²ˆì—” API ë§ê³  ìˆœìˆ˜ yfinanceë¡œ ê°€ë˜, í•œê¸€ ê°œìš”ê°€ ê¼­ í•„ìš”í•˜ë©´ ì•„ë˜ ë¡œì§ ì‚¬ìš©.
            pass 
        except:
            pass
        return None

    def get_usa_stock(self, ticker):
        """
        [ë¯¸êµ­ ì£¼ì‹] yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ì„¸ê³„ í‘œì¤€, ê°€ì¥ ì•ˆì •ì )
        ë‹¨, ê¸°ë³¸ ì •ë³´ëŠ” ì˜ì–´ë¡œ ë‚˜ì˜µë‹ˆë‹¤.
        """
        try:
            stock = yf.Ticker(ticker)
            info = stock.info
            
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨
            if 'regularMarketPrice' not in info and 'symbol' not in info:
                 return None, "yfinance ë°ì´í„° ì—†ìŒ"

            # 1. ì¢…ëª©ëª… (ì˜ì–´)
            name = info.get('longName') or info.get('shortName') or ticker
            
            # 2. ì‚°ì—…ë¶„ë¥˜ (í•œê¸€ ë§¤í•‘ ì‹œë„)
            sector_map = {
                "Technology": "ê¸°ìˆ ", "Financial Services": "ê¸ˆìœµ", "Healthcare": "í—¬ìŠ¤ì¼€ì–´",
                "Consumer Cyclical": "ê²½ê¸°ì†Œë¹„ì¬", "Communication Services": "í†µì‹ ",
                "Industrials": "ì‚°ì—…ì¬", "Consumer Defensive": "í•„ìˆ˜ì†Œë¹„ì¬", "Energy": "ì—ë„ˆì§€",
                "Basic Materials": "ì†Œì¬", "Real Estate": "ë¶€ë™ì‚°", "Utilities": "ìœ í‹¸ë¦¬í‹°"
            }
            eng_sector = info.get('sector', '')
            industry = sector_map.get(eng_sector, eng_sector) # ë§¤í•‘ ì—†ìœ¼ë©´ ì˜ì–´ ê·¸ëŒ€ë¡œ

            # 3. íšŒì‚¬ê°œìš” (ì˜ì–´ -> í•œê¸€ ë²ˆì—­ì€ êµ¬ê¸€ API ì—†ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì˜ì–´ ì›ë¬¸ or ë„¤ì´ë²„ ì‹œë„)
            summary = info.get('longBusinessSummary') or "ê°œìš” ì—†ìŒ"
            
            # [ì˜µì…˜] ì—¬ê¸°ì„œ ë„¤ì´ë²„ì— í•œ ë²ˆ ë¬¼ì–´ë´ì„œ í•œê¸€ ê°œìš”ê°€ ìˆìœ¼ë©´ ë°”ê¿”ì¹˜ê¸° í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # í•˜ì§€ë§Œ 'ë’¤ì£½ë°•ì£½'ì„ í”¼í•˜ê¸° ìœ„í•´, ë¯¸êµ­ ì£¼ì‹ì€ ì¼ë‹¨ yfinance(ì˜ì–´)ë¡œ í™•ì‹¤í•˜ê²Œ ì±„ìš°ëŠ” ê±¸ ì¶”ì²œí•©ë‹ˆë‹¤.
            
            return {
                "name": name,
                "industry": industry,
                "summary": summary
            }, "âœ… ì•¼í›„(yfinance) ì„±ê³µ"

        except Exception as e:
            return None, f"yfinance ì—ëŸ¬: {e}"

    def fetch(self, ticker):
        """í‹°ì»¤ í˜•íƒœë¥¼ ë³´ê³  í•œêµ­/ë¯¸êµ­ ë¶„ë¥˜í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘"""
        clean_ticker = ticker.strip().upper()
        
        # í•œêµ­ ì£¼ì‹ íŒë³„: 6ìë¦¬ ìˆ«ì (ë˜ëŠ” ë’¤ì— í•œê¸€ì ì•ŒíŒŒë²³)
        # ì˜ˆ: 005930, 0057H0 (ì•ŒíŒŒë²³ ì„ì¸ ì½”ë“œë„ í•œêµ­ì£¼ì‹ ë¡œì§ íƒœì›€)
        is_korea = False
        if len(clean_ticker) >= 6 and clean_ticker[:5].isdigit(): 
            is_korea = True
        
        if is_korea:
            # 005930.KS ë“± ì ‘ë¯¸ì–´ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ìˆœìˆ˜ ì½”ë“œë¡œ ë³€í™˜
            code = clean_ticker.split('.')[0]
            return self.get_korea_stock(code)
        else:
            # ë¯¸êµ­ ì£¼ì‹ (ì•ŒíŒŒë²³ í‹°ì»¤)
            return self.get_usa_stock(clean_ticker)

def main():
    print(f"ğŸš€ [Master DB] Classic Mode ì—…ë°ì´íŠ¸ ì‹œì‘ (Naver Crawling + yfinance)")
    
    try:
        notion = Client(auth=NOTION_TOKEN)
        crawler = StockCrawler()
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    next_cursor = None
    processed_count = 0
    
    while True:
        try:
            # í•„í„°: ê²€ì¦ë˜ì§€ ì•Šì€ í•­ëª©ë§Œ
            query_params = {
                "database_id": MASTER_DATABASE_ID,
                "filter": {"property": "ë°ì´í„° ìƒíƒœ", "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}},
                "page_size": 30
            }
            if next_cursor: query_params["start_cursor"] = next_cursor
            
            response = notion.databases.query(**query_params)
            pages = response.get("results", [])
            
            if not pages and processed_count == 0:
                print("âœ¨ ì—…ë°ì´íŠ¸í•  ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
                break

            for page in pages:
                page_id = page["id"]
                props = page["properties"]
                
                ticker_list = props.get("í‹°ì»¤", {}).get("title", [])
                if not ticker_list: continue
                raw_ticker = ticker_list[0].get("plain_text", "").strip().upper()
                
                # íƒ€ê²Ÿ í•„í„°ë§
                if TARGET_TICKERS and raw_ticker not in TARGET_TICKERS:
                    continue

                print(f"ğŸ” ì¡°íšŒ ì¤‘: {raw_ticker} ...")
                
                # ë°ì´í„° ìˆ˜ì§‘ (í¬ë¡¤ëŸ¬ ê²°ì •)
                data, log_msg = crawler.fetch(raw_ticker)
                
                status = ""
                upd_props = {}
                
                if data:
                    status = "âœ… ê²€ì¦ì™„ë£Œ"
                    # ìš”ì•½ë³¸ ì•ˆì „ ì²˜ë¦¬
                    summary_text = data['summary']
                    safe_summary = summary_text[:1900] + "..." if len(summary_text) > 1900 else summary_text
                    
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]},
                        "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": data['name']}}]},
                        "ì‚°ì—…ë¶„ë¥˜": {"rich_text": [{"text": {"content": data['industry']}}]}
                    }
                    if "íšŒì‚¬ê°œìš”" in props:
                        upd_props["íšŒì‚¬ê°œìš”"] = {"rich_text": [{"text": {"content": safe_summary}}]}
                        print(f"   â”” [ì™„ë£Œ] {data['name']}")
                    else:
                        print(f"   â”” [ì™„ë£Œ] {data['name']} (ê°œìš” ì—´ ì—†ìŒ)")
                else:
                    status = "âš ï¸ í™•ì¸í•„ìš”"
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]}
                    }
                    print(f"   â”” [ì‹¤íŒ¨] {log_msg}")

                notion.pages.update(page_id=page_id, properties=upd_props)
                processed_count += 1
                time.sleep(0.5) 

            if not response.get("has_more"): break
            next_cursor = response.get("next_cursor")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            break
            
    print(f"ğŸ ì‘ì—… ì™„ë£Œ: ì´ {processed_count}ê±´")

if __name__ == "__main__":
    main()
