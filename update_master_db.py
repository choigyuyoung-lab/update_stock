import os
import re
import time
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any

import requests
import pandas as pd
import FinanceDataReader as fdr
from bs4 import BeautifulSoup
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ë¡œê¹…
# ---------------------------------------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")
IS_FULL_UPDATE = os.environ.get("IS_FULL_UPDATE", "False").lower() == "true"
MAX_WORKERS = 2  # ê¸°ì¡´ ì½”ë“œ ê¸°ì¤€ ìœ ì§€

class StockAutomationEngine:
    def __init__(self):
        logger.info("ğŸ“¡ ë§ˆìŠ¤í„° ë°ì´í„° ìºì‹± ì‹œì‘ (FDR ë¦¬ìŠ¤íŒ…)...")
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        
        # ì‹œì¥ ë°ì´í„° ë¡œë“œ (KRX-DESC: ì‚°ì—…ë¶„ë¥˜ í¬í•¨)
        self.df_kr_desc = fdr.StockListing('KRX-DESC')
        self.df_etf_kr = fdr.StockListing('ETF/KR')
        self.df_nasdaq = fdr.StockListing('NASDAQ')
        self.df_nyse = fdr.StockListing('NYSE')
        try:
            self.df_etf_us = fdr.StockListing('ETF/US')
        except:
            self.df_etf_us = pd.DataFrame()
        
        self.df_us_all = pd.concat([self.df_nasdaq, self.df_nyse], ignore_index=True)

    def clean_ticker_logic(self, raw_ticker: str) -> str:
        """ê¸°ì¡´ ì½”ë“œì˜ ì •ì œ ê·œì¹™: ì ‘ë¯¸ì–´ ì œê±° ë° í•œêµ­ ìˆ«ì 6ìë¦¬ ì¶”ì¶œ"""
        ticker = raw_ticker.strip().upper()
        # 1. í•œêµ­ ì¢…ëª©: ìˆ«ì 6ìë¦¬ í¬í•¨ ì‹œ ìˆ«ìë§Œ ì¶”ì¶œ
        kr_match = re.search(r'(\d{6})', ticker)
        if kr_match: return kr_match.group(1)
        # 2. ì ‘ë¯¸ì–´ ì œê±° ë° ë³´ì •
        ticker_base = re.split(r'[-.]', ticker)[0]
        if ticker_base.isdigit() and len(ticker_base) < 6:
            return ticker_base.zfill(6)
        return ticker_base

    def fetch_wiki_data(self, google_ticker: str) -> Dict[str, str]:
        res_data = {"ind": "", "svc": ""}
        url = f"https://www.google.com/finance/quote/{google_ticker}?hl=ko"
        try:
            res = self.session.get(url, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            wiki_link = soup.find('a', href=re.compile(r'wikipedia\.org'))
            if wiki_link:
                w_res = self.session.get(wiki_link.get('href'), timeout=10)
                w_soup = BeautifulSoup(w_res.text, 'html.parser')
                infobox = w_soup.select_one('table.infobox')
                if infobox:
                    for row in infobox.find_all('tr'):
                        th, td = row.find('th'), row.find('td')
                        if th and td:
                            lbl, val = th.get_text(strip=True), td.get_text(separator=' ', strip=True)
                            if 'ì‚°ì—…' in lbl: res_data["ind"] = val
                            elif any(x in lbl for x in ['ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¶„ì•¼']): res_data["svc"] = val
        except: pass
        return res_data

    def _search_lists(self, ticker: str) -> Optional[Dict[str, Any]]:
        # í•œêµ­
        kr_col = 'Symbol' if 'Symbol' in self.df_kr_desc.columns else 'Code'
        match = self.df_kr_desc[self.df_kr_desc[kr_col].astype(str) == ticker]
        if not match.empty:
            row = match.iloc[0]
            wiki = self.fetch_wiki_data(f"{ticker}:KRX")
            return {"origin": "KR", "name": row['Name'], "market": row.get('Market', 'KRX'),
                    "sector": row.get('Industry', row.get('Sector', 'ì£¼ì‹')),
                    "industry": row.get('Industry', ''), "wiki": wiki}
        # ë¯¸êµ­ ì£¼ì‹
        match = self.df_us_all[self.df_us_all['Symbol'].astype(str) == ticker]
        if not match.empty:
            row = match.iloc[0]
            wiki = self.fetch_wiki_data(ticker)
            mkt = "NASDAQ" if ticker in self.df_nasdaq['Symbol'].values else "NYSE"
            return {"origin": "US", "name": row['Name'], "market": mkt,
                    "sector": row.get('Industry', 'ì£¼ì‹'), "industry": row.get('Industry', ''), "wiki": wiki}
        return None

    def find_info(self, raw_ticker: str) -> Optional[Dict[str, Any]]:
        # 1. ì›í˜• ê²€ìƒ‰ -> 2. ì •ì œ ê²€ìƒ‰
        res = self._search_lists(raw_ticker.strip().upper())
        if not res:
            res = self._search_lists(self.clean_ticker_logic(raw_ticker))
        return res

def process_page(page, engine, notion):
    pid = page["id"]
    props = page["properties"]
    ticker_title = props.get("í‹°ì»¤", {}).get("title", [])
    if not ticker_title: return
    raw_ticker = ticker_title[0]["plain_text"].strip()
    
    try:
        data = engine.find_info(raw_ticker)
        if not data:
            notion.pages.update(page_id=pid, properties={"ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": "FDR ì •ë³´ì—†ìŒ"}}]}})
            return

        now = datetime.now().isoformat()
        # str() ë³€í™˜ìœ¼ë¡œ int64 ì—ëŸ¬ ë°©ì§€
        upd = {
            "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": str(data["name"])}}]},
            "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": "FDRí™•ì¸ë¨"}}]},
            "ë°ì´í„° ìƒíƒœ": {"select": {"name": "âœ… ê²€ì¦ì™„ë£Œ"}},
            "ì—…ë°ì´íŠ¸ ì¼ì": {"date": {"start": now}}
        }

        # ì—´ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ ë° í†µí•© í•„ë“œ ì—…ë°ì´íŠ¸
        if "Market" in props: upd["Market"] = {"select": {"name": str(data["market"])}}
        if "ì‚°ì—…ë¶„ì•¼" in props: upd["ì‚°ì—…ë¶„ì•¼"] = {"rich_text": [{"text": {"content": str(data["wiki"]["ind"])}}]}
        if "ì„œë¹„ìŠ¤" in props: upd["ì„œë¹„ìŠ¤"] = {"rich_text": [{"text": {"content": str(data["wiki"]["svc"])}}]}

        # ì‹œì¥ë³„ ìƒì„¸ í•„ë“œ
        if data["origin"] == "KR":
            if "KR_ì‚°ì—…" in props: upd["KR_ì‚°ì—…"] = {"rich_text": [{"text": {"content": str(data["industry"])}}]}
            if "KR_ì„¹í„°" in props: upd["KR_ì„¹í„°"] = {"rich_text": [{"text": {"content": str(data["sector"])}}]}
        else:
            if "US_ì„¹í„°" in props: upd["US_ì„¹í„°"] = {"rich_text": [{"text": {"content": str(data["sector"])}}]}
            if "US_ì—…ì¢…" in props: upd["US_ì—…ì¢…"] = {"rich_text": [{"text": {"content": str(data["industry"])}}]}

        notion.pages.update(page_id=pid, properties=upd)
        logger.info(f"DONE: {raw_ticker}")
    except Exception as e:
        logger.error(f"FAIL {raw_ticker}: {e}")

def main():
    logger.info(f"Automation Start [Full Update: {IS_FULL_UPDATE}]")
    notion, engine = Client(auth=NOTION_TOKEN), StockAutomationEngine()
    cursor = None
    while True:
        params = {"database_id": MASTER_DATABASE_ID, "page_size": 100}
        if cursor: params["start_cursor"] = cursor
        
        # ê¸°ì¡´ì˜ ì „ì²´ ì—…ë°ì´íŠ¸ ë¶„ê¸° ë¡œì§ ì™„ë²½ ì´ì‹
        if not IS_FULL_UPDATE:
            params["filter"] = {"property": "ë°ì´í„° ìƒíƒœ", "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}}
        
        response = notion.databases.query(**params)
        pages = response.get("results", [])
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            for page in pages:
                executor.submit(process_page, page, engine, notion)
                time.sleep(0.4) # ê¸°ì¡´ì˜ ì•ˆì •ì ì¸ ìŠ¬ë¦½ íƒ€ì„ ìœ ì§€
        
        if not response.get("has_more"): break
        cursor = response.get("next_cursor")
    logger.info("All Jobs Done.")

if __name__ == "__main__":
    main()
