import os
import re
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any

import requests
import pandas as pd
import FinanceDataReader as fdr
from bs4 import BeautifulSoup
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ë¡œê¹… (Python 3.10+ ìµœì í™”)
# ---------------------------------------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")
IS_FULL_UPDATE = os.environ.get("IS_FULL_UPDATE", "False").lower() == "true"
MAX_WORKERS = 4 

class StockAutomationEngine:
    def __init__(self):
        logger.info("ğŸ“¡ ë§ˆìŠ¤í„° ë°ì´í„° ìºì‹± ë° ì •ì œ ë¡œì§ ì¤€ë¹„...")
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        
        # ì‹œì¥ ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ ì„±ê³µ í”„ë¡œì íŠ¸ ë§¥ë½ ë°˜ì˜)
        self.df_kr_desc = fdr.StockListing('KRX-DESC')
        self.df_etf_kr = fdr.StockListing('ETF/KR')
        self.df_nasdaq = fdr.StockListing('NASDAQ')
        self.df_nyse = fdr.StockListing('NYSE')
        try:
            self.df_etf_us = fdr.StockListing('ETF/US')
        except:
            self.df_etf_us = pd.DataFrame()
        
        self.df_us_all = pd.concat([self.df_nasdaq, self.df_nyse], ignore_index=True)

    def clean_ticker_logic(self, raw_ticker: str) -> str:
        """ê¸°ì¡´ ì½”ë“œì˜ ì •ì œ ê·œì¹™ ì™„ë²½ ì´ì‹: ì ‘ë¯¸ì–´ ì œê±° ë° í•œêµ­ ìˆ«ì ì¶”ì¶œ"""
        ticker = raw_ticker.strip().upper()
        
        # 1. í•œêµ­ ì¢…ëª© íŠ¹í™”: ìˆ«ì 6ìë¦¬ê°€ í¬í•¨ëœ ê²½ìš° ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: A060310 -> 060310)
        kr_match = re.search(r'(\d{6})', ticker)
        if kr_match:
            return kr_match.group(1)
            
        # 2. ì ‘ë¯¸ì–´(. , -) ì œê±° ê·œì¹™ (ê¸°ì¡´ ë¡œì§ ì´ì‹)
        ticker_base = re.split(r'[-.]', ticker)[0]
        
        # 3. 6ìë¦¬ ë¯¸ë§Œ ìˆ«ì ë³´ì •
        if ticker_base.isdigit() and len(ticker_base) < 6:
            return ticker_base.zfill(6)
            
        return ticker_base

    def fetch_wiki_data(self, google_ticker: str) -> Dict[str, str]:
        """êµ¬ê¸€ íŒŒì´ë‚¸ìŠ¤ë¥¼ ê²½ìœ í•˜ì—¬ í†µí•© 'ì‚°ì—…ë¶„ì•¼'ì™€ 'ì„œë¹„ìŠ¤' ìˆ˜ì§‘"""
        res_data = {"ind": "", "svc": ""}
        url = f"https://www.google.com/finance/quote/{google_ticker}?hl=ko"
        try:
            res = self.session.get(url, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            wiki_link = soup.find('a', href=re.compile(r'wikipedia\.org'))
            if wiki_link:
                w_res = self.session.get(wiki_link.get('href'), timeout=10)
                w_soup = BeautifulSoup(w_res.text, 'html.parser')
                infobox = w_soup.select_one('table.infobox')
                if infobox:
                    for row in infobox.find_all('tr'):
                        th, td = row.find('th'), row.find('td')
                        if th and td:
                            lbl, val = th.get_text(strip=True), td.get_text(separator=' ', strip=True)
                            if 'ì‚°ì—…' in lbl: res_data["ind"] = val
                            elif any(x in lbl for x in ['ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¶„ì•¼']): res_data["svc"] = val
        except: pass
        return res_data

    def _search_lists(self, ticker: str) -> Optional[Dict[str, Any]]:
        """ë©”ëª¨ë¦¬ì— ë¡œë“œëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‹°ì»¤ ë§¤ì¹­ (í•œêµ­ -> ë¯¸êµ­ ìˆœ)"""
        # í•œêµ­ ì£¼ì‹
        t_col = 'Symbol' if 'Symbol' in self.df_kr_desc.columns else 'Code'
        match = self.df_kr_desc[self.df_kr_desc[t_col].astype(str) == ticker]
        if not match.empty:
            row = match.iloc[0]
            wiki = self.fetch_wiki_data(f"{ticker}:KRX")
            return {"origin": "KR", "name": row['Name'], "market": row.get('Market', 'KRX'),
                    "sector": row.get('Industry', row.get('Sector', 'ì£¼ì‹')),
                    "industry": row.get('Industry', ''), "wiki": wiki}
        
        # í•œêµ­ ETF
        match = self.df_etf_kr[self.df_etf_kr['Symbol'].astype(str) == ticker] if 'Symbol' in self.df_etf_kr.columns else pd.DataFrame()
        if not match.empty:
            row = match.iloc[0]
            return {"origin": "KR", "name": row['Name'], "market": "ETF/KR",
                    "sector": "ETF", "industry": row.get('Category', 'êµ­ë‚´ETF'), "wiki": {"ind": "", "svc": ""}}

        # ë¯¸êµ­ ì£¼ì‹
        match = self.df_us_all[self.df_us_all['Symbol'].astype(str) == ticker]
        if not match.empty:
            row = match.iloc[0]
            wiki = self.fetch_wiki_data(ticker)
            mkt = "NASDAQ" if ticker in self.df_nasdaq['Symbol'].values else "NYSE"
            return {"origin": "US", "name": row['Name'], "market": mkt,
                    "sector": row.get('Industry', 'ì£¼ì‹'), "industry": row.get('Industry', ''), "wiki": wiki}
        
        # ë¯¸êµ­ ETF
        if not self.df_etf_us.empty:
            match = self.df_etf_us[self.df_etf_us['Symbol'].astype(str) == ticker]
            if not match.empty:
                row = match.iloc[0]
                return {"origin": "US", "name": row['Name'], "market": "ETF/US",
                        "sector": "ETF", "industry": "ë¯¸êµ­ETF", "wiki": {"ind": "", "svc": ""}}
        return None

    def find_info(self, raw_ticker: str) -> Optional[Dict[str, Any]]:
        # 1. ì›í˜• ê²€ìƒ‰ (BRK.B ë“± ëŒ€ì‘)
        result = self._search_lists(raw_ticker.strip().upper())
        if result: return result
        
        # 2. ì‹¤íŒ¨ ì‹œ ì •ì œ ê·œì¹™ ì ìš© ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
        clean = self.clean_ticker_logic(raw_ticker)
        if clean != raw_ticker.strip().upper():
            return self._search_lists(clean)
        return None

def process_page(notion, engine, page):
    pid = page["id"]
    raw_ticker = page["properties"]["í‹°ì»¤"]["title"][0]["plain_text"].strip()
    
    try:
        data = engine.find_info(raw_ticker)
        if not data:
            notion.pages.update(page_id=pid, properties={"ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": "FDR ì •ë³´ì—†ìŒ"}}]}})
            return

        # ê³µí†µ ì—…ë°ì´íŠ¸ (ì¢…ëª©ëª…, Market, ì‚°ì—…ë¶„ì•¼, ì„œë¹„ìŠ¤ í†µí•©)
        upd_props = {
            "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": data["name"]}}]},
            "Market": {"select": {"name": data["market"]}}, 
            "ì‚°ì—…ë¶„ì•¼": {"rich_text": [{"text": {"content": data["wiki"]["ind"]}}]},
            "ì„œë¹„ìŠ¤": {"rich_text": [{"text": {"content": data["wiki"]["svc"]}}]},
            "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": "FDRí™•ì¸ë¨"}}]},
            "ë°ì´í„° ìƒíƒœ": {"select": {"name": "âœ… ê²€ì¦ì™„ë£Œ"}},
            "ì—…ë°ì´íŠ¸ ì¼ì": {"date": {"start": datetime.now().isoformat()}}
        }

        # ì‹œì¥ë³„ ìƒì„¸ ì •ë³´ ë¶„ë¦¬ ê¸°ë¡
        if data["origin"] == "KR":
            upd_props.update({
                "KR_ì‚°ì—…": {"rich_text": [{"text": {"content": data["industry"]}}]},
                "KR_ì„¹í„°": {"rich_text": [{"text": {"content": data["sector"]}}]},
                "US_ì„¹í„°": {"rich_text": []}, "US_ì—…ì¢…": {"rich_text": []}
            })
        else:
            upd_props.update({
                "US_ì„¹í„°": {"rich_text": [{"text": {"content": data["sector"]}}]},
                "US_ì—…ì¢…": {"rich_text": [{"text": {"content": data["industry"]}}]},
                "KR_ì‚°ì—…": {"rich_text": []}, "KR_ì„¹í„°": {"rich_text": []}
            })

        notion.pages.update(page_id=pid, properties=upd_props)
        logger.info(f"SUCCESS: {raw_ticker}")
    except Exception as e:
        logger.error(f"ERROR {raw_ticker}: {e}")

def main():
    notion = Client(auth=NOTION_TOKEN)
    engine = StockAutomationEngine()
    cursor = None
    while True:
        params = {"database_id": MASTER_DATABASE_ID, "page_size": 100}
        if cursor: params["start_cursor"] = cursor
        if not IS_FULL_UPDATE:
            params["filter"] = {"property": "ë°ì´í„° ìƒíƒœ", "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}}
        
        response = notion.databases.query(**params)
        pages = response.get("results", [])
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            for page in pages: executor.submit(process_page, notion, engine, page)
        if not response.get("has_more"): break
        cursor = response.get("next_cursor")

if __name__ == "__main__":
    main()
