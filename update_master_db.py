import os
import time
import requests
import re
import yfinance as yf
from bs4 import BeautifulSoup
from notion_client import Client

# ---------------------------------------------------------
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# ---------------------------------------------------------
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")

# [ìˆ˜ì •ë¨] GitHub Secrets ì´ë¦„ì¸ GOOGLE_CXë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
GOOGLE_CX = os.environ.get("GOOGLE_CX")

# [ì„¤ì •] ì „ì²´ ì—…ë°ì´íŠ¸ (ë¹„ì›Œë‘ë©´ ì „ì²´ ì‹¤í–‰)
TARGET_TICKERS = []

# ì‹œìŠ¤í…œ ìƒìˆ˜
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'

# ì•¼í›„ ì‚°ì—…ë¶„ë¥˜ í•œê¸€ ë§¤í•‘
YAHOO_SECTOR_MAP = {
    "Technology": "ê¸°ìˆ ", "Financial Services": "ê¸ˆìœµ", "Healthcare": "í—¬ìŠ¤ì¼€ì–´",
    "Consumer Cyclical": "ê²½ê¸°ì†Œë¹„ì¬", "Communication Services": "í†µì‹  ì„œë¹„ìŠ¤",
    "Industrials": "ì‚°ì—…ì¬", "Consumer Defensive": "í•„ìˆ˜ì†Œë¹„ì¬", "Energy": "ì—ë„ˆì§€",
    "Basic Materials": "ì†Œì¬", "Real Estate": "ë¶€ë™ì‚°", "Utilities": "ìœ í‹¸ë¦¬í‹°"
}

class StockCrawler:
    def __init__(self):
        self.headers = {'User-Agent': USER_AGENT}

    # ------------------------------------------------------------------
    # [NEW] ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹(ë¯¸êµ­) ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ëª¨ë°”ì¼ API ì‚¬ìš©)
    # ------------------------------------------------------------------
    def fetch_naver_us_stock(self, ticker):
        """
        ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹ ëª¨ë°”ì¼ APIë¥¼ í†µí•´ 'í•œê¸€' ê¸°ì—… ê°œìš”ì™€ ì„¹í„° ì •ë³´ë¥¼ ê°€ì ¸ì˜´
        """
        try:
            # ë„¤ì´ë²„ëŠ” ë¯¸êµ­ ì£¼ì‹ ë’¤ì— ë³´í†µ .O (NYSE/AMEX/NASDAQ í†µí•©) ë“±ì„ ë¶™ì„
            # API: https://api.stock.naver.com/stock/{ticker}.O/basic
            
            # 1ì°¨ ì‹œë„: í‹°ì»¤ + .O (ë„¤ì´ë²„ì˜ ì¼ë°˜ì ì¸ ë¯¸êµ­ì£¼ì‹ ì‹ë³„ì)
            search_ticker = f"{ticker}.O"
            url = f"https://api.stock.naver.com/stock/{search_ticker}/basic"
            
            res = requests.get(url, headers=self.headers, timeout=5)
            
            # ë§Œì•½ .Oë¡œ ì•ˆ ë˜ë©´(404 ë“±), í‹°ì»¤ ê·¸ëŒ€ë¡œ í•œ ë²ˆ ë” ì‹œë„ (í˜¹ì‹œë‚˜ í•´ì„œ)
            if res.status_code != 200:
                url = f"https://api.stock.naver.com/stock/{ticker}/basic"
                res = requests.get(url, headers=self.headers, timeout=5)
                if res.status_code != 200:
                    return None # ë„¤ì´ë²„ì— ì •ë³´ ì—†ìŒ -> ì•¼í›„ë¡œ ë„˜ê¸°ì

            data = res.json()
            
            # ë°ì´í„° íŒŒì‹±
            stock_item = data.get('stockItem', {})
            
            # 1. ì¢…ëª©ëª… (í•œê¸€ ì´ë¦„ ìš°ì„ )
            kor_name = stock_item.get('stockName', ticker)
            eng_name = stock_item.get('engStockName', ticker)
            final_name = kor_name if kor_name else eng_name
            
            # 2. ì‚°ì—…ë¶„ë¥˜ (í•œê¸€ ì„¹í„°)
            industry_map = stock_item.get('industryCodeType', {})
            industry = industry_map.get('industryGroupKor', "ë¯¸êµ­ì£¼ì‹") 

            # 3. íšŒì‚¬ê°œìš” (í•œê¸€ ì„¤ëª…!)
            summary = stock_item.get('corpSummary', "")
            
            # ìš”ì•½ì´ ì—†ë”ë¼ë„ ì´ë¦„/ì‚°ì—…ì´ë¼ë„ ê±´ì¡Œìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            return {
                "name": final_name,
                "industry": industry,
                "summary": summary,
                "source": "ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹(API)"
            }

        except Exception as e:
            # ì—ëŸ¬ ë‚˜ë©´ ì¡°ìš©íˆ ì•¼í›„ë¡œ ë„˜ê¹€
            return None

    # ------------------------------------------------------------------
    # [ê¸°ëŠ¥] êµ¬ê¸€ ê²€ìƒ‰ ê²€ì¦
    # ------------------------------------------------------------------
    def verify_with_google(self, ticker, fetched_name):
        if not GOOGLE_API_KEY or not GOOGLE_CX:
            return True, ""
        try:
            query = f"{ticker} ì£¼ì‹" if re.search(r'\d', ticker) else f"{ticker} stock"
            url = "https://www.googleapis.com/customsearch/v1"
            params = {'key': GOOGLE_API_KEY, 'cx': GOOGLE_CX, 'q': query, 'num': 2}
            
            res = requests.get(url, params=params, timeout=5)
            if res.status_code != 200: return True, "" 

            items = res.json().get('items', [])
            if not items: return False, "(êµ¬ê¸€ê²°ê³¼ ì—†ìŒ)"

            core_name = fetched_name.split()[0].replace(',', '').lower()
            is_matched = False
            for item in items:
                title = item.get('title', '').lower()
                snippet = item.get('snippet', '').lower()
                if (core_name in title or core_name in snippet) or \
                   (ticker.lower().split('.')[0] in title):
                    is_matched = True
                    break
            
            if is_matched: return True, "+ êµ¬ê¸€ê²€ì¦ë¨"
            else: return False, "(êµ¬ê¸€ê²€ì¦ ì‹¤íŒ¨)"
        except Exception:
            return True, "" 

    # ------------------------------------------------------------------
    # í¬ë¡¤ë§ ë¡œì§ (ë„¤ì´ë²„ êµ­ë‚´ PC)
    # ------------------------------------------------------------------
    def fetch_naver_crawling(self, ticker):
        try:
            url = f"https://finance.naver.com/item/main.naver?code={ticker}"
            res = requests.get(url, headers=self.headers, timeout=10)
            res.encoding = res.apparent_encoding 
            if res.status_code != 200: return None
            
            soup = BeautifulSoup(res.text, 'html.parser')
            name_tag = soup.select_one('.wrap_company h2 a')
            if not name_tag: return None 
            name = name_tag.text.strip()

            industry = "í•œêµ­ì¦ì‹œ"
            try:
                ind_tag = soup.select_one('div.section.trade_compare h4 em a')
                if ind_tag: industry = ind_tag.text.strip()
            except: pass

            summary = ""
            summary_div = soup.select_one('#summary_info p')
            if summary_div: summary = summary_div.text.strip()
            
            return {
                "name": name,
                "industry": industry,
                "summary": summary,
                "source": "ë„¤ì´ë²„ ì •ë³´"
            }
        except Exception: pass
        return None

    # ------------------------------------------------------------------
    # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ (ë°±ì—…ìš©)
    # ------------------------------------------------------------------
    def fetch_yahoo(self, ticker):
        try:
            stock = yf.Ticker(ticker)
            info = stock.info
            if 'regularMarketPrice' not in info and 'symbol' not in info: return None

            name = info.get('longName') or info.get('shortName') or ticker
            eng_sector = info.get('sector', '')
            industry = YAHOO_SECTOR_MAP.get(eng_sector, eng_sector)
            summary = info.get('longBusinessSummary', '')

            return {
                "name": name,
                "industry": industry,
                "summary": summary,
                "source": "ì•¼í›„ ì •ë³´(ì˜ë¬¸)"
            }
        except Exception: pass
        return None

    # ------------------------------------------------------------------
    # [ìˆ˜ì •ë¨] ë°ì´í„° ìˆ˜ì§‘ ì´ê´„ (ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹ ìš°ì„  ì ìš©)
    # ------------------------------------------------------------------
    def get_data(self, ticker):
        raw_ticker = ticker.strip().upper()
        
        is_korea = False
        search_code = raw_ticker

        if (len(raw_ticker) == 6 and raw_ticker[0].isdigit()) or \
           raw_ticker.endswith('.KS') or raw_ticker.endswith('.KQ'):
            is_korea = True
            if '.' in raw_ticker: search_code = raw_ticker.split('.')[0]
        else:
            if '.' in raw_ticker: search_code = raw_ticker.split('.')[0]

        data = None
        
        if is_korea:
            # 1. í•œêµ­ ì£¼ì‹ -> ë„¤ì´ë²„ êµ­ë‚´
            data = self.fetch_naver_crawling(search_code)
        else:
            # 2. ë¯¸êµ­/í•´ì™¸ ì£¼ì‹ -> [NEW] ë„¤ì´ë²„ í•´ì™¸ì£¼ì‹ API ë¨¼ì € ì‹œë„!
            data = self.fetch_naver_us_stock(search_code)
            
            # ë„¤ì´ë²„ì— ì—†ìœ¼ë©´ -> ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ë¡œ ë°±ì—…
            if not data:
                data = self.fetch_yahoo(search_code)

        if data:
            is_verified, msg = self.verify_with_google(search_code, data['name'])
            if msg:
                data['source'] = f"{data['source']} {msg}"
            data['is_verified'] = is_verified

        return data

def main():
    print(f"ğŸš€ [Master DB] ì—…ë°ì´íŠ¸ ì‹œì‘ (ë„¤ì´ë²„ í•œê¸€ì •ë³´ ìš°ì„ ëª¨ë“œ)")
    
    try:
        notion = Client(auth=NOTION_TOKEN)
        crawler = StockCrawler()
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    next_cursor = None
    processed_count = 0
    
    while True:
        try:
            # [í•„í„°] 'ê²€ì¦ì™„ë£Œ'ê°€ ì•„ë‹Œ ê²ƒë§Œ ê°€ì ¸ì˜¤ê¸°
            query_params = {
                "database_id": MASTER_DATABASE_ID,
                "filter": {"property": "ë°ì´í„° ìƒíƒœ", "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}},
                "page_size": 50
            }
            if next_cursor: query_params["start_cursor"] = next_cursor
            
            response = notion.databases.query(**query_params)
            pages = response.get("results", [])
            
            if not pages and processed_count == 0:
                print("âœ¨ ì—…ë°ì´íŠ¸í•  ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
                break
            if not pages: break

            for page in pages:
                page_id = page["id"]
                props = page["properties"]
                
                ticker_list = props.get("í‹°ì»¤", {}).get("title", [])
                if not ticker_list: continue
                raw_ticker = ticker_list[0].get("plain_text", "").strip().upper()
                
                if TARGET_TICKERS and raw_ticker not in TARGET_TICKERS: continue

                print(f"ğŸ” ì—…ë°ì´íŠ¸ ì¤‘: {raw_ticker} ...")
                
                data = crawler.get_data(raw_ticker)
                
                status = ""
                log_msg = ""
                upd_props = {}
                
                if data:
                    if data.get('is_verified', True):
                        status = "âœ… ê²€ì¦ì™„ë£Œ"
                    else:
                        status = "âš ï¸ í™•ì¸í•„ìš”"
                    
                    log_msg = data['source']
                    summary_text = data['summary']
                    safe_summary = summary_text[:1900] + "..." if summary_text and len(summary_text) > 1900 else (summary_text or "")
                    
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]},
                        "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": data['name']}}]},
                        "ì‚°ì—…ë¶„ë¥˜": {"rich_text": [{"text": {"content": data['industry']}}]}
                    }
                    if "íšŒì‚¬ê°œìš”" in props:
                        upd_props["íšŒì‚¬ê°œìš”"] = {"rich_text": [{"text": {"content": safe_summary}}]}
                    
                    print(f"   â”” ì™„ë£Œ {data['name']} ({log_msg})")
                else:
                    status = "âš ï¸ í™•ì¸í•„ìš”"
                    log_msg = "ë°ì´í„° ì—†ìŒ"
                    upd_props = {
                        "ë°ì´í„° ìƒíƒœ": {"select": {"name": status}},
                        "ê²€ì¦ë¡œê·¸": {"rich_text": [{"text": {"content": log_msg}}]}
                    }
                    print(f"   â”” ì‹¤íŒ¨ {log_msg}")

                notion.pages.update(page_id=page_id, properties=upd_props)
                processed_count += 1
                time.sleep(0.5) 

            if not response.get("has_more"): break
            next_cursor = response.get("next_cursor")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            break
            
    print(f"ğŸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì´ {processed_count}ê±´")

if __name__ == "__main__":
    main()
