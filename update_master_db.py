import os, re, time, logging, io
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any, List

import requests
import pandas as pd
import FinanceDataReader as fdr
from pykrx import stock
from notion_client import Client

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")
IS_FULL_UPDATE = os.environ.get("IS_FULL_UPDATE", "False").lower() == "true"

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

class StockAutomationEngine:
    def __init__(self):
        logger.info("ğŸ“¡ 4ëŒ€ ìš°ëŸ‰ì£¼ ë¦¬ìŠ¤íŠ¸ ë° ì‹œì¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        
        # 1. ê¸°ì´ˆ ë°ì´í„° ë¡œë“œ
        self.df_krx = fdr.StockListing('KRX') # Market ì»¬ëŸ¼ í¬í•¨
        
        # 2. 4ëŒ€ ìš°ëŸ‰ì£¼ ë§µ êµ¬ì¶• (ì„±ê³µ ì¡°í•©)
        self.blue_chip_map = {
            "S&P 500": self._get_sp500(),
            "NASDAQ 100": self._get_nas100(),
            "KOSPI 200": self._get_ks200(),
            "KOSDAQ GLOBAL": self._get_kglobal()
        }
        
        for k, v in self.blue_chip_map.items():
            logger.info(f"âœ… {k}: {len(v)}ê°œ ë¡œë“œ ì™„ë£Œ")

    def _get_sp500(self) -> List[str]:
        try: return fdr.StockListing('S&P500')['Symbol'].tolist()
        except: return []

    def _get_nas100(self) -> List[str]:
        try:
            url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
            res = self.session.get(url, timeout=10)
            df = pd.read_html(io.StringIO(res.text))[4]
            col = 'Ticker' if 'Ticker' in df.columns else 'Symbol'
            return df[col].tolist()
        except: return []

    def _get_ks200(self) -> List[str]:
        for i in range(10): # ìµœê·¼ 10ì¼ íƒìƒ‰ (0ê°œ ë¡œë“œ ë°©ì§€)
            date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
            res = stock.get_index_portfolio_deposit_file("1028", date)
            if len(res) > 0: return res
        return []

    def _get_kglobal(self) -> List[str]:
        # Market ì»¬ëŸ¼ì—ì„œ 'KOSDAQ GLOBAL' í•„í„°ë§ (ì‚¬ìš©ì ë°œê²¬ ë¡œì§)
        target = self.df_krx[self.df_krx['Market'].str.contains('KOSDAQ GLOBAL', case=False, na=False)]
        col = 'Code' if 'Code' in target.columns else 'Symbol'
        return target[col].tolist()

    def clean_ticker(self, raw_ticker: str) -> str:
        """í‹°ì»¤ ì •ì œ ë¡œì§ (Python 3.10+)"""
        t = str(raw_ticker).strip().upper()
        if match := re.search(r'(\d{6})', t):
            return match.group(1)
        return re.split(r'[-.]', t)[0]

def process_page(page, engine, notion):
    pid = page["id"]
    props = page["properties"]
    
    # í‹°ì»¤ ê°€ì ¸ì˜¤ê¸°
    ticker_rich = props.get("í‹°ì»¤", {}).get("title", [])
    if not ticker_rich: return
    raw_ticker = ticker_rich[0]["plain_text"].strip()
    clean_t = engine.clean_ticker(raw_ticker)

    # ìš°ëŸ‰ì£¼ ì²´í¬ (4ê°œ ë¦¬ìŠ¤íŠ¸ ëŒ€ì¡°) 
    bc_tags = []
    for label, ticker_list in engine.blue_chip_map.items():
        if clean_t in ticker_list:
            bc_tags.append({"name": label})

    # ì—…ë°ì´íŠ¸ ì†ì„± êµ¬ì„±
    update_props = {
        "ë°ì´í„° ìƒíƒœ": {"select": {"name": "âœ… ê²€ì¦ì™„ë£Œ"}},
        "ì—…ë°ì´íŠ¸ ì¼ì": {"date": {"start": datetime.now().isoformat()}}
    }
    
    # ìš°ëŸ‰ì£¼ ì—´ì´ ìˆì„ ê²½ìš°ì—ë§Œ íƒœê·¸ ì‚½ì…
    if "ìš°ëŸ‰ì£¼" in props:
        update_props["ìš°ëŸ‰ì£¼"] = {"multi_select": bc_tags}

    try:
        notion.pages.update(page_id=pid, properties=update_props)
        logger.info(f"âœ… {raw_ticker} ({clean_t}) ì—…ë°ì´íŠ¸ ì„±ê³µ | íƒœê·¸: {[t['name'] for t in bc_tags]}")
    except Exception as e:
        logger.error(f"âŒ {raw_ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def main():
    notion = Client(auth=NOTION_TOKEN)
    engine = StockAutomationEngine()
    
    cursor = None
    while True:
        query_params = {"database_id": MASTER_DATABASE_ID, "page_size": 100}
        if cursor: query_params["start_cursor"] = cursor
        
        # ìˆ˜ë™ ì‹¤í–‰(Full)ì´ ì•„ë‹ˆë©´ ê²€ì¦ì™„ë£Œê°€ ì•„ë‹Œ ê²ƒë§Œ í•„í„°ë§
        if not IS_FULL_UPDATE:
            query_params["filter"] = {
                "property": "ë°ì´í„° ìƒíƒœ",
                "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}
            }
        
        response = notion.databases.query(**query_params)
        pages = response.get("results", [])
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
        with ThreadPoolExecutor(max_workers=5) as executor:
            for page in pages:
                executor.submit(process_page, page, engine, notion)
                time.sleep(0.3) # API ì†ë„ ì œí•œ ë°©ì§€
        
        if not response.get("has_more"): break
        cursor = response.get("next_cursor")

if __name__ == "__main__":
    main()
