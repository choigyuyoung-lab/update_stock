import os, re, time, logging, io
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any, List

import requests
import pandas as pd
import FinanceDataReader as fdr
from pykrx import stock
from notion_client import Client
from bs4 import BeautifulSoup

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
MASTER_DATABASE_ID = os.environ.get("MASTER_DATABASE_ID")
IS_FULL_UPDATE = os.environ.get("IS_FULL_UPDATE", "False").lower() == "true"

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

class StockAutomationEngine:
    def __init__(self):
        logger.info("ğŸ“¡ ì£¼ì‹ ë° ETF í†µí•© ë°ì´í„° ë¡œë“œ ì¤‘...")
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        
        # 1. ì¼ë°˜ ì£¼ì‹ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        self.df_krx = fdr.StockListing('KRX') 
        self.df_nasdaq = fdr.StockListing('NASDAQ')
        self.df_nyse = fdr.StockListing('NYSE')
        
        # 2. [ì¶”ê°€] ETF ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (êµ­ë‚´/ë¯¸êµ­ í†µí•©) 
        try:
            self.df_etf_kr = fdr.StockListing('ETF/KR')
            self.df_etf_us = fdr.StockListing('ETF/US')
            logger.info(f"âœ… ETF ë°ì´í„° ë¡œë“œ ì™„ë£Œ (êµ­ë‚´: {len(self.df_etf_kr)}, ë¯¸êµ­: {len(self.df_etf_us)})")
        except Exception as e:
            logger.error(f"âŒ ETF ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.df_etf_kr = pd.DataFrame()
            self.df_etf_us = pd.DataFrame()

        self.df_us_all = pd.concat([self.df_nasdaq, self.df_nyse], ignore_index=True)
        
        # 3. 4ëŒ€ ìš°ëŸ‰ì£¼ ë§µ êµ¬ì¶•
        self.blue_chip_map = {
            "S&P 500": self._get_sp500(),
            "NASDAQ 100": self._get_nas100(),
            "KOSPI 200": self._get_ks200(),
            "KOSDAQ GLOBAL": self._get_kglobal()
        }

    def _get_sp500(self) -> List[str]:
        try: return fdr.StockListing('S&P500')['Symbol'].tolist()
        except: return []

    def _get_nas100(self) -> List[str]:
        try:
            url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
            res = self.session.get(url, timeout=10)
            df = pd.read_html(io.StringIO(res.text))[4]
            col = 'Ticker' if 'Ticker' in df.columns else 'Symbol'
            return df[col].tolist()
        except: return []

    def _get_ks200(self) -> List[str]:
        for i in range(10):
            date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
            res = stock.get_index_portfolio_deposit_file("1028", date)
            if len(res) > 0: return res
        return []

    def _get_kglobal(self) -> List[str]:
        target = self.df_krx[self.df_krx['Market'].str.contains('KOSDAQ GLOBAL', case=False, na=False)]
        col = 'Code' if 'Code' in target.columns else 'Symbol'
        return target[col].tolist()

    def fetch_wiki_info(self, ticker: str, origin: str) -> Dict[str, str]:
        res_data = {"ind": "", "svc": ""}
        search_ticker = f"{ticker}:KRX" if origin == "KR" else ticker
        url = f"https://www.google.com/finance/quote/{search_ticker}?hl=ko"
        try:
            res = self.session.get(url, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            wiki_link = soup.find('a', href=re.compile(r'wikipedia\.org'))
            if wiki_link:
                w_res = self.session.get(wiki_link.get('href'), timeout=10)
                w_soup = BeautifulSoup(w_res.text, 'html.parser')
                infobox = w_soup.select_one('table.infobox')
                if infobox:
                    for row in infobox.find_all('tr'):
                        th, td = row.find('th'), row.find('td')
                        if th and td:
                            lbl, val = th.get_text(strip=True), td.get_text(separator=' ', strip=True)
                            if 'ì‚°ì—…' in lbl: res_data["ind"] = val
                            elif any(x in lbl for x in ['ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¶„ì•¼']): res_data["svc"] = val
        except: pass
        return res_data

    def get_stock_detail(self, clean_t: str) -> Dict[str, Any]:
        """ì£¼ì‹ ë° ETF í†µí•© ê²€ìƒ‰ ë¡œì§"""
        # 1. í•œêµ­ ì‹œì¥ ê²€ìƒ‰ (ì£¼ì‹ -> ETF ìˆœ)
        kr_match = self.df_krx[self.df_krx['Code'] == clean_t]
        if not kr_match.empty:
            row = kr_match.iloc[0]
            return {"name": row['Name'], "market": str(row['Market']), "origin": "KR", "wiki": self.fetch_wiki_info(clean_t, "KR")}
        
        # [ì¶”ê°€] í•œêµ­ ETF ê²€ìƒ‰
        if not self.df_etf_kr.empty:
            etf_kr_match = self.df_etf_kr[self.df_etf_kr['Symbol'] == clean_t]
            if not etf_kr_match.empty:
                row = etf_kr_match.iloc[0]
                return {"name": row['Name'], "market": "ETF(KR)", "origin": "KR", "wiki": {"ind": "ETF", "svc": "êµ­ë‚´ ìƒì¥ì§€ìˆ˜í€ë“œ"}}

        # 2. ë¯¸êµ­ ì‹œì¥ ê²€ìƒ‰ (ì£¼ì‹ -> ETF ìˆœ)
        us_match = self.df_us_all[self.df_us_all['Symbol'] == clean_t]
        if not us_match.empty:
            row = us_match.iloc[0]
            mkt = "NASDAQ" if clean_t in self.df_nasdaq['Symbol'].values else "NYSE"
            return {"name": row['Name'], "market": mkt, "origin": "US", "wiki": self.fetch_wiki_info(clean_t, "US")}
        
        # [ì¶”ê°€] ë¯¸êµ­ ETF ê²€ìƒ‰
        if not self.df_etf_us.empty:
            etf_us_match = self.df_etf_us[self.df_etf_us['Symbol'] == clean_t]
            if not etf_us_match.empty:
                row = etf_us_match.iloc[0]
                return {"name": row['Name'], "market": "ETF(US)", "origin": "US", "wiki": {"ind": "ETF", "svc": "ë¯¸êµ­ ìƒì¥ì§€ìˆ˜í€ë“œ"}}

        return {"name": "", "market": "ê¸°íƒ€", "origin": "", "wiki": {"ind": "", "svc": ""}}

    def clean_ticker(self, raw_ticker: str) -> str:
        t = str(raw_ticker).strip().upper()
        if match := re.search(r'(\d{6})', t): return match.group(1)
        return re.split(r'[-.]', t)[0]

def process_page(page, engine, client):
    pid, props = page["id"], page["properties"]
    ticker_rich = props.get("í‹°ì»¤", {}).get("title", [])
    if not ticker_rich: return
    
    raw_ticker = ticker_rich[0]["plain_text"].strip()
    clean_t = engine.clean_ticker(raw_ticker)

    info = engine.get_stock_detail(clean_t)
    bc_tags = [{"name": label} for label, lst in engine.blue_chip_map.items() if clean_t in lst]

    update_props = {
        "ì¢…ëª©ëª…": {"rich_text": [{"text": {"content": info["name"]}}]},
        "Market": {"select": {"name": info["market"]}},
        "ì‚°ì—…ë¶„ì•¼": {"rich_text": [{"text": {"content": info["wiki"]["ind"]}}]},
        "ì„œë¹„ìŠ¤": {"rich_text": [{"text": {"content": info["wiki"]["svc"]}}]},
        "ë°ì´í„° ìƒíƒœ": {"select": {"name": "âœ… ê²€ì¦ì™„ë£Œ"}},
        "ì—…ë°ì´íŠ¸ ì¼ì": {"date": {"start": datetime.now().isoformat()}}
    }
    
    if "ìš°ëŸ‰ì£¼" in props:
        update_props["ìš°ëŸ‰ì£¼"] = {"multi_select": bc_tags}

    try:
        client.pages.update(page_id=pid, properties=update_props)
        logger.info(f"âœ… {raw_ticker} ({info['name']}) ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ {raw_ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def main():
    client = Client(auth=NOTION_TOKEN) 
    engine = StockAutomationEngine()
    
    cursor = None
    while True:
        query_params = {"database_id": MASTER_DATABASE_ID, "page_size": 100}
        if cursor: query_params["start_cursor"] = cursor
        if not IS_FULL_UPDATE:
            query_params["filter"] = {"property": "ë°ì´í„° ìƒíƒœ", "select": {"does_not_equal": "âœ… ê²€ì¦ì™„ë£Œ"}}
        
        response = client.databases.query(**query_params) 
        pages = response.get("results", [])
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            for page in pages:
                executor.submit(process_page, page, engine, client)
                time.sleep(0.3)
        
        if not response.get("has_more"): break
        cursor = response.get("next_cursor")

if __name__ == "__main__":
    main()
